def reward(self, action=None):
    # Initialize reward components dictionary and total reward
    r_total = 0.0
    r_dict = {}

    # Get cube position
    cube_pos = np.array(self.sim.data.body_xpos[self.cube_body_id])
    cube_height = cube_pos[2]
    
    # Get gripper to cube distance
    gripper_to_cube = self._gripper_to_target(self.robots[0].gripper, self.cube, target_type='body', return_distance=True)
    
    # Check if the cube is grasped
    cube_grasped = self._check_grasp(self.robots[0].gripper, self.cube)
    
    # 1. Reward for reaching the cube - decreases exponentially with distance
    reach_temp = 10.0  # Temperature parameter for reach reward
    r_reach = np.exp(-reach_temp * gripper_to_cube)
    r_dict['r_reach'] = r_reach
    
    # 2. Reward for grasping the cube - largest reward component
    r_grasp = 2.0 if cube_grasped else 0.0
    r_dict['r_grasp'] = r_grasp
    
    # 3. Reward for lifting the cube only if it's grasped
    # Higher reward for lifting higher, up to a reasonable height
    if cube_grasped:
        # Get lift height relative to the table
        lift_height = cube_height - self.initial_cube_height
        # Smooth bounded reward that increases with height up to a point
        lift_temp = 5.0  # Temperature parameter for lift reward
        r_lift = 2.0 * np.tanh(lift_temp * lift_height)
        r_dict['r_lift'] = r_lift
    else:
        r_dict['r_lift'] = 0.0
        
    # 4. Success reward - cube is grasped and lifted to a good height
    min_lift_height = 0.05  # Minimum height to consider cube successfully picked up
    success = cube_grasped and (cube_height > self.initial_cube_height + min_lift_height)
    r_success = 3.0 if success else 0.0
    r_dict['r_success'] = r_success
    
    # Calculate total reward
    r_total = r_reach + r_grasp + r_dict['r_lift'] + r_success
    
    # Apply reward scaling if specified
    if self.reward_scale is not None:
        # Maximum possible reward: r_reach(1.0) + r_grasp(2.0) + r_lift(2.0) + r_success(3.0) = 8.0
        scalar_value = 8.0
        r_total *= self.reward_scale / scalar_value
    
    return r_total, r_dict

def _check_success(self):
    # Get cube position
    cube_pos = np.array(self.sim.data.body_xpos[self.cube_body_id])
    cube_height = cube_pos[2]
    
    # Check if cube is grasped
    cube_grasped = self._check_grasp(self.robots[0].gripper, self.cube)
    
    # Success is when the cube is grasped and lifted above a threshold
    min_lift_height = 0.05  # Minimum height to consider the cube lifted
    return cube_grasped and (cube_height > self.initial_cube_height + min_lift_height)